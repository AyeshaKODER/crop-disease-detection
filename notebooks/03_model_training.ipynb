{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ac9d7",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sys.path last entries: ['C:\\\\Users\\\\anask\\\\miniconda3\\\\envs\\\\crop_tf\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor', 'C:\\\\Users\\\\anask\\\\crop-disease-detection', 'C:\\\\Users\\\\anask\\\\crop-disease-detection\\\\src']\n",
      "TensorFlow version: 2.18.1\n",
      "GPU Available: False\n",
      "\n",
      "ðŸ”„ Creating data generators (batch_size=32)...\n",
      "Found 49327 images belonging to 38 classes.\n",
      "Found 15062 images belonging to 38 classes.\n",
      "Found 15077 images belonging to 38 classes.\n",
      "âœ… Train samples: 49327\n",
      "âœ… Val samples: 15062\n",
      "âœ… Test samples: 15077\n",
      "âœ… Number of classes: 38\n",
      "\n",
      "âœ… Data loaded:\n",
      "   Train: 49327 images\n",
      "   Val: 15062 images\n",
      "   Test: 15077 images\n",
      "   Classes: 38\n",
      "\n",
      "======================================================================\n",
      "Testing custom_cnn\n",
      "======================================================================\n",
      "\n",
      "âœ… Built model: custom_cnn\n",
      "   Total params: 1,450,822\n",
      "   Trainable params: 1,447,878\n",
      "\n",
      "âœ… Model compiled with learning_rate=0.001\n",
      "Epoch 1/3\n",
      "\u001b[1m 6/50\u001b[0m \u001b[32mâ”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m8:23\u001b[0m 11s/step - accuracy: 0.0233 - loss: 5.7792 - precision: 0.0052 - recall: 8.6806e-04 - top_3_accuracy: 0.0641    "
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 03 - Model Training & Experimentation\n",
    "# This notebook tests different model architectures and hyperparameters\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure project root (crop-disease-detection) is in sys.path\n",
    "project_root = Path(os.getcwd()).resolve().parent  # one level up from 'notebooks'\n",
    "sys.path.append(str(project_root))\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "print(\"Sys.path last entries:\", sys.path[-3:])\n",
    "\n",
    "from model import ModelBuilder\n",
    "from data_loader import PlantVillageDataLoader\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Load Data\n",
    "\n",
    "# %%\n",
    "# Paths\n",
    "# Paths\n",
    "RAW_DATA_PATH = project_root / \"src/data/raw/plantvillage-dataset/plantvillage dataset/color\"\n",
    "PROCESSED_DATA_PATH = project_root / \"src/data/processed\"\n",
    "\n",
    "# Ensure processed directories exist\n",
    "for subdir in [\"train\", \"val\", \"test\"]:\n",
    "    (PROCESSED_DATA_PATH / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "loader = PlantVillageDataLoader(\n",
    "    raw_data_path=str(RAW_DATA_PATH),\n",
    "    processed_data_path=str(PROCESSED_DATA_PATH),\n",
    "    img_size=(224, 224),\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create data generators\n",
    "train_gen, val_gen, test_gen = loader.create_data_generators(\n",
    "    batch_size=32,\n",
    "    augment_train=True\n",
    ")\n",
    "\n",
    "# Load class names\n",
    "class_file = PROCESSED_DATA_PATH / 'class_names.json'\n",
    "if class_file.exists():\n",
    "    with open(class_file, 'r') as f:\n",
    "        class_names = json.load(f)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{class_file} not found. Make sure dataset is processed correctly.\")\n",
    "\n",
    "print(f\"\\nâœ… Data loaded:\")\n",
    "print(f\"   Train: {train_gen.samples} images\")\n",
    "print(f\"   Val: {val_gen.samples} images\")\n",
    "print(f\"   Test: {test_gen.samples} images\")\n",
    "print(f\"   Classes: {len(class_names)}\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Quick Model Comparison\n",
    "\n",
    "# %%\n",
    "def quick_train_test(model_name, epochs=3):\n",
    "    print(f\"\\n{'='*70}\\nTesting {model_name}\\n{'='*70}\")\n",
    "\n",
    "    model = ModelBuilder.build(\n",
    "        model_name=model_name,\n",
    "        input_shape=(224, 224, 3),\n",
    "        num_classes=len(class_names)\n",
    "    )\n",
    "    ModelBuilder.compile_model(model, learning_rate=0.001)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        steps_per_epoch=min(50, train_gen.samples // train_gen.batch_size),\n",
    "        validation_steps=min(20, val_gen.samples // val_gen.batch_size),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_top3, val_precision, val_recall = model.evaluate(\n",
    "        val_gen, steps=min(20, val_gen.samples // val_gen.batch_size), verbose=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'params': model.count_params(),\n",
    "        'val_acc': val_acc,\n",
    "        'val_loss': val_loss\n",
    "    }\n",
    "\n",
    "models_to_test = ['custom_cnn', 'mobilenet_v2']\n",
    "results = []\n",
    "\n",
    "for m in models_to_test:\n",
    "    try:\n",
    "        results.append(quick_train_test(m))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {m}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Final Training\n",
    "\n",
    "# %%\n",
    "BEST_CONFIG = {\n",
    "    'model': 'mobilenet_v2',\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 5,\n",
    "}\n",
    "\n",
    "final_model = ModelBuilder.build(\n",
    "    model_name=BEST_CONFIG['model'],\n",
    "    input_shape=(224, 224, 3),\n",
    "    num_classes=len(class_names),\n",
    "    trainable_layers=20,\n",
    "    dropout_rate=0.5\n",
    ")\n",
    "ModelBuilder.compile_model(final_model, learning_rate=BEST_CONFIG['learning_rate'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "print(\"\\nðŸš€ Starting final training...\")\n",
    "history = final_model.fit(\n",
    "    train_gen,\n",
    "    epochs=BEST_CONFIG['epochs'],\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Plot Training\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Accuracy Plot\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Loss Plot\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Save plot image\n",
    "plot_path = project_root / \"models\" / \"training_curve.png\"\n",
    "plt.savefig(plot_path)\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Training curve saved at {plot_path}\")\n",
    "# %% [markdown]\n",
    "# ## 4. Evaluate on Test Set\n",
    "\n",
    "# %%\n",
    "test_loss, test_acc, test_top3, test_precision, test_recall = final_model.evaluate(test_gen)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Loss: {test_loss:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Save Model\n",
    "\n",
    "# %%\n",
    "models_dir = project_root / 'models'\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "final_model.save(models_dir / 'final_mobilenetv2.h5')\n",
    "print(f\"âœ… Model saved at {models_dir / 'final_mobilenetv2.h5'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Crop Disease TF Conda",
   "language": "python",
   "name": "crop_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
