{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753ac9d7",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sys.path last entries: ['C:\\\\Users\\\\anask\\\\miniconda3\\\\envs\\\\crop_tf\\\\Lib\\\\site-packages\\\\setuptools\\\\_vendor', 'C:\\\\Users\\\\anask\\\\crop-disease-detection', 'C:\\\\Users\\\\anask\\\\crop-disease-detection\\\\src']\n",
      "TensorFlow version: 2.18.1\n",
      "GPU Available: False\n",
      "\n",
      "ðŸ”„ Creating data generators (batch_size=32)...\n",
      "Found 49327 images belonging to 38 classes.\n",
      "Found 15062 images belonging to 38 classes.\n",
      "Found 15077 images belonging to 38 classes.\n",
      "âœ… Train samples: 49327\n",
      "âœ… Val samples: 15062\n",
      "âœ… Test samples: 15077\n",
      "âœ… Number of classes: 38\n",
      "\n",
      "âœ… Data loaded:\n",
      "   Train: 49327 images\n",
      "   Val: 15062 images\n",
      "   Test: 15077 images\n",
      "   Classes: 38\n",
      "\n",
      "======================================================================\n",
      "Testing custom_cnn\n",
      "======================================================================\n",
      "\n",
      "âœ… Built model: custom_cnn\n",
      "   Total params: 1,450,822\n",
      "   Trainable params: 1,447,878\n",
      "\n",
      "âœ… Model compiled with learning_rate=0.001\n",
      "Epoch 1/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 8s/step - accuracy: 0.1339 - loss: 4.7604 - precision: 0.2696 - recall: 0.0695 - top_3_accuracy: 0.2805 - val_accuracy: 0.1484 - val_loss: 4.3734 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_top_3_accuracy: 0.3281\n",
      "Epoch 2/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 7s/step - accuracy: 0.2237 - loss: 4.0323 - precision: 0.3812 - recall: 0.1294 - top_3_accuracy: 0.4087 - val_accuracy: 0.0000e+00 - val_loss: 7.0824 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_top_3_accuracy: 0.0000e+00\n",
      "Epoch 3/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m368s\u001b[0m 7s/step - accuracy: 0.2412 - loss: 3.9156 - precision: 0.4246 - recall: 0.1531 - top_3_accuracy: 0.4394 - val_accuracy: 0.0000e+00 - val_loss: 9.1187 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_top_3_accuracy: 0.0000e+00\n",
      "\n",
      "======================================================================\n",
      "Testing mobilenet_v2\n",
      "======================================================================\n",
      "\n",
      "âœ… Built model: mobilenet_v2\n",
      "   Total params: 3,056,998\n",
      "   Trainable params: 2,004,070\n",
      "\n",
      "âœ… Model compiled with learning_rate=0.001\n",
      "Epoch 1/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 2s/step - accuracy: 0.4212 - loss: 3.4438 - precision: 0.7368 - recall: 0.3044 - top_3_accuracy: 0.5819 - val_accuracy: 0.1297 - val_loss: 12.5581 - val_precision: 0.1405 - val_recall: 0.1219 - val_top_3_accuracy: 0.3234\n",
      "Epoch 2/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 3s/step - accuracy: 0.6394 - loss: 2.3453 - precision: 0.8241 - recall: 0.5300 - top_3_accuracy: 0.8275 - val_accuracy: 0.3281 - val_loss: 11.3131 - val_precision: 0.3571 - val_recall: 0.3281 - val_top_3_accuracy: 0.3281\n",
      "Epoch 3/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 4s/step - accuracy: 0.7212 - loss: 2.0224 - precision: 0.8236 - recall: 0.6187 - top_3_accuracy: 0.8875 - val_accuracy: 0.1953 - val_loss: 11.2912 - val_precision: 0.1962 - val_recall: 0.1937 - val_top_3_accuracy: 0.3359\n",
      "          model   params   val_acc   val_loss\n",
      "0    custom_cnn  1450822  0.000000   9.118718\n",
      "1  mobilenet_v2  3056998  0.195312  11.291221\n",
      "\n",
      "âœ… Built model: mobilenet_v2\n",
      "   Total params: 3,056,998\n",
      "   Trainable params: 2,004,070\n",
      "\n",
      "âœ… Model compiled with learning_rate=0.001\n",
      "\n",
      "ðŸš€ Starting final training...\n",
      "Epoch 1/20\n",
      "\u001b[1m1542/1542\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3019s\u001b[0m 2s/step - accuracy: 0.8275 - loss: 1.2980 - precision: 0.8869 - recall: 0.7861 - top_3_accuracy: 0.9444 - val_accuracy: 0.7794 - val_loss: 1.8896 - val_precision: 0.7970 - val_recall: 0.7745 - val_top_3_accuracy: 0.8810 - learning_rate: 0.0010\n",
      "Epoch 2/20\n",
      "\u001b[1m1542/1542\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4063s\u001b[0m 3s/step - accuracy: 0.9037 - loss: 0.6197 - precision: 0.9262 - recall: 0.8843 - top_3_accuracy: 0.9822 - val_accuracy: 0.8749 - val_loss: 0.7513 - val_precision: 0.8886 - val_recall: 0.8682 - val_top_3_accuracy: 0.9725 - learning_rate: 0.0010\n",
      "Epoch 3/20\n",
      "\u001b[1m1542/1542\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2964s\u001b[0m 2s/step - accuracy: 0.9161 - loss: 0.5163 - precision: 0.9344 - recall: 0.9005 - top_3_accuracy: 0.9856 - val_accuracy: 0.8747 - val_loss: 0.7680 - val_precision: 0.8846 - val_recall: 0.8706 - val_top_3_accuracy: 0.9709 - learning_rate: 0.0010\n",
      "Epoch 4/20\n",
      "\u001b[1m1542/1542\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2640s\u001b[0m 2s/step - accuracy: 0.9265 - loss: 0.4607 - precision: 0.9430 - recall: 0.9122 - top_3_accuracy: 0.9880 - val_accuracy: 0.9123 - val_loss: 0.5470 - val_precision: 0.9200 - val_recall: 0.9076 - val_top_3_accuracy: 0.9864 - learning_rate: 0.0010\n",
      "Epoch 5/20\n",
      "\u001b[1m 753/1542\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m14:13\u001b[0m 1s/step - accuracy: 0.9318 - loss: 0.4350 - precision: 0.9485 - recall: 0.9209 - top_3_accuracy: 0.9879"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # 03 - Model Training & Experimentation\n",
    "# This notebook tests different model architectures and hyperparameters\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Ensure project root (crop-disease-detection) is in sys.path\n",
    "project_root = Path(os.getcwd()).resolve().parent  # one level up from 'notebooks'\n",
    "sys.path.append(str(project_root))\n",
    "sys.path.append(str(project_root / \"src\"))\n",
    "\n",
    "print(\"Sys.path last entries:\", sys.path[-3:])\n",
    "\n",
    "from model import ModelBuilder\n",
    "from data_loader import PlantVillageDataLoader\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", len(tf.config.list_physical_devices('GPU')) > 0)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 1. Load Data\n",
    "\n",
    "# %%\n",
    "# Paths\n",
    "# Paths\n",
    "RAW_DATA_PATH = project_root / \"src/data/raw/plantvillage-dataset/plantvillage dataset/color\"\n",
    "PROCESSED_DATA_PATH = project_root / \"src/data/processed\"\n",
    "\n",
    "# Ensure processed directories exist\n",
    "for subdir in [\"train\", \"val\", \"test\"]:\n",
    "    (PROCESSED_DATA_PATH / subdir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "loader = PlantVillageDataLoader(\n",
    "    raw_data_path=str(RAW_DATA_PATH),\n",
    "    processed_data_path=str(PROCESSED_DATA_PATH),\n",
    "    img_size=(224, 224),\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Create data generators\n",
    "train_gen, val_gen, test_gen = loader.create_data_generators(\n",
    "    batch_size=32,\n",
    "    augment_train=True\n",
    ")\n",
    "\n",
    "# Load class names\n",
    "class_file = PROCESSED_DATA_PATH / 'class_names.json'\n",
    "if class_file.exists():\n",
    "    with open(class_file, 'r') as f:\n",
    "        class_names = json.load(f)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{class_file} not found. Make sure dataset is processed correctly.\")\n",
    "\n",
    "print(f\"\\nâœ… Data loaded:\")\n",
    "print(f\"   Train: {train_gen.samples} images\")\n",
    "print(f\"   Val: {val_gen.samples} images\")\n",
    "print(f\"   Test: {test_gen.samples} images\")\n",
    "print(f\"   Classes: {len(class_names)}\")\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Quick Model Comparison\n",
    "\n",
    "# %%\n",
    "def quick_train_test(model_name, epochs=3):\n",
    "    print(f\"\\n{'='*70}\\nTesting {model_name}\\n{'='*70}\")\n",
    "\n",
    "    model = ModelBuilder.build(\n",
    "        model_name=model_name,\n",
    "        input_shape=(224, 224, 3),\n",
    "        num_classes=len(class_names)\n",
    "    )\n",
    "    ModelBuilder.compile_model(model, learning_rate=0.001)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        steps_per_epoch=min(50, train_gen.samples // train_gen.batch_size),\n",
    "        validation_steps=min(20, val_gen.samples // val_gen.batch_size),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc, val_top3, val_precision, val_recall = model.evaluate(\n",
    "        val_gen, steps=min(20, val_gen.samples // val_gen.batch_size), verbose=0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'params': model.count_params(),\n",
    "        'val_acc': val_acc,\n",
    "        'val_loss': val_loss\n",
    "    }\n",
    "\n",
    "models_to_test = ['custom_cnn', 'mobilenet_v2']\n",
    "results = []\n",
    "\n",
    "for m in models_to_test:\n",
    "    try:\n",
    "        results.append(quick_train_test(m))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {m}: {e}\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Final Training\n",
    "\n",
    "# %%\n",
    "BEST_CONFIG = {\n",
    "    'model': 'mobilenet_v2',\n",
    "    'learning_rate': 0.001,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 20\n",
    "}\n",
    "\n",
    "final_model = ModelBuilder.build(\n",
    "    model_name=BEST_CONFIG['model'],\n",
    "    input_shape=(224, 224, 3),\n",
    "    num_classes=len(class_names),\n",
    "    trainable_layers=20,\n",
    "    dropout_rate=0.5\n",
    ")\n",
    "ModelBuilder.compile_model(final_model, learning_rate=BEST_CONFIG['learning_rate'])\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)\n",
    "]\n",
    "\n",
    "print(\"\\nðŸš€ Starting final training...\")\n",
    "history = final_model.fit(\n",
    "    train_gen,\n",
    "    epochs=BEST_CONFIG['epochs'],\n",
    "    validation_data=val_gen,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# %%\n",
    "# Plot Training\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Val')\n",
    "plt.legend(); plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Val')\n",
    "plt.legend(); plt.title('Loss')\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Evaluate on Test Set\n",
    "\n",
    "# %%\n",
    "test_loss, test_acc, test_top3, test_precision, test_recall = final_model.evaluate(test_gen)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Loss: {test_loss:.4f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Save Model\n",
    "\n",
    "# %%\n",
    "models_dir = project_root / 'models'\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "final_model.save(models_dir / 'final_mobilenetv2.h5')\n",
    "print(f\"âœ… Model saved at {models_dir / 'final_mobilenetv2.h5'}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Crop Disease TF Conda",
   "language": "python",
   "name": "crop_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
